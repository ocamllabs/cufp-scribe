% This is file JFP2egui.tex
% release v1.02, 27th September 2001
%   (based on JFPguide.tex v1.11 for LaTeX 2.09)
% Copyright (C) 2001 Cambridge University Press

\NeedsTeXFormat{LaTeX2e}

\documentclass{jfp1}
\bibliographystyle{jfp}
\usepackage{url}

%%% Macros for the guide only %%%
\providecommand\AMSLaTeX{AMS\,\LaTeX}
\newcommand\eg{\emph{e.g.}\ }
\newcommand\etc{\emph{etc.}}
\newcommand\bcmdtab{\noindent\bgroup\tabcolsep=0pt%
  \begin{tabular}{@{}p{10pc}@{}p{20pc}@{}}}
\newcommand\ecmdtab{\end{tabular}\egroup}
\newcommand\rch[1]{$\longrightarrow\rlap{$#1$}$\hspace{1em}}
\newcommand\lra{\ensuremath{\quad\longrightarrow\quad}}

\title[Commercial Users of Functional Programming 2012]
      {Commercial Users of Functional Programming Workshop Report}

\author[Michael Sperber and Anil Madhavapeddy]
       {MICHAEL SPERBER\\
         Active Group GmbH, Hornbergstra\ss{}e 49\\
         70794 Filderstadt, Germany\\
         ANIL MADHAVAPEDDY\\
        Computer Laboratory, University of Cambridge\\ 
        15 JJ Thomson Avenue, Cambridge CB3 0FD, UK}

\jdate{May 2012}
\pubyear{2012}
\pagerange{\pageref{firstpage}--\pageref{lastpage}}

\begin{document}

\label{firstpage}
\maketitle

\section{Overview}

Commercial Users of Functional Programming (CUFP) is a yearly workshop
that is aimed at the community of software developers who use functional
programming in real-world settings.  This scribe report covers the talks
that were delivered at the 2012 workshop, which was held in association
with ICFP in Copenhagen.  The goal of the report is to give the reader
a sense of what went on, rather than to reproduce the full details
of the talks.  Videos and slides from all the talks are available online at \url{http://cufp.org}.

\section{Keynote: Adopting Functional Programming}

Kresten Krab Thorup, CTO of Trifork, Aarhus gave the keynote address,
and took us on the voyage he had taken from being on ``object head''
to ``Erlang land.''  Thorup's foundational training in software
development was all in terms of object-oriented methodologies.  He
went on to work on Objective C for NeXT, afterwards took his Ph.D.\
and then founded Trifork, an IT services company with now about 250
employees that develops software solutions, provides training, and
organizes several well-respected conferences.

While Trifork originally capitalized almost exclusively on its Java
expertise, it now successfully applies Erlang in large-scale
industrial projects.  Thorup described (taking cues from anthropology)
how many organizations have not been able to make such transitions
easily: Groups tend to gather around an idea that keeps them together,
and try to keep new ideas at bay.  This makes it difficult for
long-time OO developers to adopt functional programming.

Trifork managed to stay flexible by making learning about new ideas
and communicating them part of their regular operation: Everyone at
Trifork should spend 10\% of their time in the structured exchange of
knowledge, by giving presentations, organizing meetings, give training
classes, or organizing conferences.

Thorup reviewed object-oriented programming and the ecosystem around
it to show how it had become successful: Through an intuitive idea~--
``an object is an independent encapsulated entity that inteprets
inputs on its own account''~-- but also because of the availability of
thinking tools: graphical notation for design, tools for mapping those
designs to programs, books on comon problems akin to ``Design
Patterns''~\cite{GammaHelmJohnsonVlissides1995}, analysis methods for producing systems,
and standardized qualification processes.

However, Thorup sees a series problem with the object-oriented model,
as objects have no coherent model of time, and no good way to compose
behaviors over time.  With the rise of multicore and distributed
computing, these become increasingly important.  Erlang, supporting
functional programming and an actor model for concurrency, parallelism
and distribution, addresses this issue.  Thorup stressed that Erlang
is not primarily a functional programming language, but that
functional programming helps Erlang meet its requirements: being a
language for writing robust distributed applications.

Thorup described large-scale projects done using Erlang: One for
managing health-care records in Denmark, and one for sharing data
among ``sometimes connected devices'' such as a cell phones at a music
festival.

Thorup concluded by noting that two fundamental classes of problems in
software development require different classses of solutions:
\textit{Interactive systems} with multiple parties are fundamentally
stateful, and where developers should understand the handling of
state~-- for those problems, actors are a good model.
\textit{Transformational systems} map input to output, where
developers want to abstract over the details of hardware utilization,
the handling of mutable state and coordination.

\section{Jane Street Status Report}

Jane Street is a quantitative proprietary trading firm that has been a
well-known user and supporter of OCaml.  Yaron Minsky reviewed the
past decade of OCaml use at Jane Street.

Jane Street has three kinds of requirements on their own software:
\begin{description}
\item[Correctness] Jane Street trades billions of dollars every day~--
  much more than the company is worth.  Hence, a software error can
  have disastrous consequences.
\item[Agility] Jane Street needs to be able to adapt the software
  quickly to exploit new market opportunities as they are found.
\item[Performance] The software needs to quickly to exploit market
  opportunities.
\end{description}
%
Jane Street has written OCaml code for a number of application areas:
research tools for investiagting trading strategies, trading systems
(replacing legay systems written in VBA/Excel) that make trades
automatically, order gateways that implement protocols to interact
with markets, post-trade software to analyze and clean up completed
trades, systems infrastructure to manage systems, development tools,
trading tools, tools for managing market-data and desk infrastructure.

Minsky could not remember a crucial error in the software that
happened in production: Code at Jane Street generally fails by turning
off the system, which is acceptable in this environment.  Jane
Street's user interfaces are all text-based, and written using
Curses~-- this ``prevents bad UX designers from doing UX.''

Another important that favors OCaml is how the type system eases large
refactoring projects: The type system catches most mistakes that occur
in the middle of such projects.  The type system helps programmers
write readable, explicit code, which is more important than great
productivity increases or extremely concise programs.

Jane Street has developed a number of generally useful libraries for
OCaml, many of which are open
source.\footnote{http://janestreet.github.io/} In particular,
\textit{Core} is an enhanced ``standard library,'' meant to the
minimalistic libraries that ship with OCaml.  \textit{Async} is a
library with monadic concurrency abstractions, similar to available in
other functional languages such as
F\#~\cite{Syme:2011:FAP:1946313.1946334}.  \textit{Incremental}
describes large-scale computations with small updates.
\textit{Catalog} is a publish/subscribe system.  \textit{Nile} is a
distributed message-passing library.

In summary, Jane Street is fully committed to OCaml, and will continue
to do its development in OCaml.  Jane Street will continue to
contribute to open-source projects, and to collaborate with others
working on or in OCaml.

\section{Transmitting customised ads to set-top boxes with Erlang}

Macías Lopez, David Cabrero and Laura M.\ Castro from the University
of A Coruña reported on \textit{ADVERTISE}
project~\cite{Lopez:2012:DDA:2370776.2370800,
  Lopez:2012:FTC:2364489.2364498}.  \textit{ADVERTISE} is a
distributed system for transmission of customised ads to TV set-top
boxes via the TV network of a cable provider.  The system~-- entirely
written in Erlang~-- compiles events, emits ``advertising signals'' to
set-top boxes, and collects statistics about how many times specific
ads were displayed on consumer boxes.  ADVERTISE sends ads to more
than 100,000 clients.

Lopez reported on the difficulties of developing and deploying such a
large-scale system.  In particular, after the original system
implementation, the customer only provided hardware that did not
satisfy the original minimum specifications.  Moreover, the network
exhibits frequent node failures and netsplits, which disrupted the
operation of the original system.  Thus, while Erlang was a good
choice for implementing the system, merely using Erlang does not make
a distributed system robust in highly unreliable environments.
ADVERTISE yielded insights into best practices for implementing
distributed systems in such environments.

Netsplits in particular are problematic, as nodes may incorrectly
conclude other nodes are down, and then compete for control of the
network.  This may lead to data inconsistencies and duplicate
implementations of responsibilities assumed to be unique. An ADVERTISE
node, when it loses network connectivity, immediately suspends
execution and waits until it is restored, choosing consistency over
availability in such scenarios to avoid corrupting advertising
campaigns.

\section{Haskell for XenClient}

Matthias Görgens reported on using Haskell in the XenClient project at
Citrix: XenClient is a virtual-machine manager for clients, primarily
laptops in corporate and government environments, where XenClient
offers functionality different from the long-established XenServer,
such as trusted-computing support with hard-drive encryption and
native graphics performance.

The XenClient management stack consists of many daemons that commicate
via D-Bus and V4V (a VM-to-VM communications protocol).  Originally,
many of the daemons were written using Ruby, but a rising bug count
motivated the development team to look for alternatives, particularly
statically-typed languages to catch more bugs at development time.
Some daemons were then rewritten in Haskell.  By now, there are about
25,000 loc in Haskell in the system.  The XenClient daemons are
typically long-running, perform short bursts of communication and
computation upon a request discovered via polling, do not hold much
state and are restartable: Haskell is well-suited for this kind of
application.

As XenServer already uses OCaml for its management toolstack, it is a
bit surprising that XenClient chose Haskell: Görgens cited personal
preferences, the availability of more libraries, and the fact that
Haskell ``relieves pressure to share code with XenServer.''

Görgens also cited a few problems with using Haskell: XenClient found
it difficult to handle IO-heavy workloads, making Haskell work with
the OpenEmbedded build system in use in XenClient, and the
successfully train developers not yet familiar with functional
programming.

\section{Functional Programming @ Ghent IT Valley}

Romain Slootmaekers and Nicolas Trangez of Incubaid Research Lab
reported on using OCaml for implementing a distributed storage
service.  Incubaid Research Lab is an incubator laboratory for startup
companies.

In 2009, Amplidata~-- one of those spinoffs~-- was working on a
\textit{dispersed storage system} (DSS).  The system consists of a
multi-stage pipeline involving metadata storage, encoding and
decoding, storage management, and the backend disks.  At the time,
development on the storage-management component, written in C++, had
stalled: There were problems with resource management and threads, the
software had many bugs, and its object model had poor locality, which
led to poor performance.  Slootmaekers was able to (correctly)
re-implement the storage component in OCaml within two days, which led
to Amplidata considering using languages other than C++ for system
development.

The original reimplementation of the storage component had to be done
quickly, and was able to leverage OCaml's object-oriented substrate to
duplicate the architecture of the C++ original.  Also, the existence
of precise specifications and a test suite helped speed the rewrite.

The successor version of the system was then re-implemented mostly in
OCaml, and involved more leisurely and more complete refactoring.  The
rewrite used the \textit{Lwt}~\cite{Vouillon:2008:LCT:1411304.1411307}
library, and was delightfully painless.  Performance improved more
than twofold, and Amplidata was able to preserve code size while
adding significant features.  In particular, the newly written Arakoon
distributed key-value store was developed to hold the system's metadata.

OCaml helped developers through type inference, a fast compiler that
produces sufficiently fast code, the convenient C FFI, and the help
the type system gives when refactoring.  Downsides are poor tool
support, a scarce and fragmented library landscape, problems with
multicore support, that the object-oriented model which does not fit
well with the rest of the language.  Slootmaekers also cited the lack
of visual tools to talk about system architecture as a notable
problem.

In conclusion, Slootmaekers noted that any sufficiently large project
should be ready to use more than one language, and that functional
programming and distributed systems are a good match.

\section{From Streams to Functions (and Back Again)}

Frank McCabe of Starview, Inc.\ reported on Star, a new programming
language, that is part of Starview's event-processing platform.  (Star
is available by request the author via \url{www.star-lang.com}.)  The
purpose of Starview's platform is to provide \textit{operational
  intelligence}: to notice when a significant business event happened,
and to decide what to do about it, in real time.  The Star language
was developed to express this intelligence: It started out as
``StarRules,'' a simple language based on a ``on pattern do
something'' construct.  It could perform straightforward statistical
processing and infer significant events from event data.

StarRules's first application was scheduling in the semiconductor
industry.  In this domain, it is not enough for software to make
simple inferences from the data: It needs to make complex decision in
the face of an ever-changing environment, where machines frequently
break, invalidating any long-term plans.  The software needed here did
not fit StarRules's ``on pattern do'' construct.  Consequently,
Starview decided to turn StarRules into a general-purpose language,
and renamed it to Star.

A number of requirements shaped Star's design: Star needed to support
different programming styles in use at Starview.  The
semiconductor-fab scheduling application demanded safety, as errors in
the deployed software can be extremely costly.  Moreover, it needed to
satisfy modest real-time requirements: the software needs to be fast
enough to provide useful output before it is obsolete.

McCabe then made the following basic design decisions for Star: Star
is strongly to help with safety, but also to support tooling and help
communication in teams.  To avoid the bureaucracy of dealing with
types in Java, the language has type inference.  The type system is
based on algebraic types rather than objects, and has no
\texttt{null}.  (This decision was controversial within Starview,
which is still in many ways a ``Java house.'')

Star then amalgamated influences from various languages, in particular
functions as an organizing principle from other functional languages,
macros from April~\cite{fgm-klc:95} and Lisp to support syntatic
extensibity, as well as the Concurrent ML substrate for parallelism
and concurrency~\cite{Reppy1999}.  The type system borrows much from
Haskell: Star's type contracts are a variant of Haskell's type
classes~\cite{WadlerBlott1989}.  Star also includes influences from
Prolog and SQL.  Moreover, its actors based on \textit{speech
  actions}~\cite{searle:69} provide a mechanism for implementing
agent-like entities. Star is designed to be readable rather than
concise: This makes its texture distinct from other functional
languages such as Haskell or ML.

The combination of functions, macros and overloading provides a
coherent methodology for implementing DSLs in Star: A developer can
start with an ontological commitment in her problem domain, provide
appropriate syntax, which is translated into a macro invocation, which
is turned into function invocations, which are often backed by
contracts.  In particular, actors are implemented this way, as is
higher-level functionality for analytics and event processing.


\section{Functional Big-Data Genomics}

Ashish Agarwal reported on joint work with Sebastien Mondet, Paul
Scheid, Avid Madar, Richard Bonneau<sup>1, Jane Carlton,. and Kristin
C.\ Gunsalus at New York University: the Genomics Sequencing Core used
to enable entry, storage and analysis of genomic sequencing data,
implemented in OCaml.

Since the sequencing of the human genome in 2000, modern sequencing
equipment has been getting faster at high rates: Whereas storage costs
per amount of data are halving every 14 months, the data that
accumulates in genome sequencing doubles in volume every five months.
This places high demands on the computational infrastructure used to
process sequencing data.  In particular, where the sequencing
itself~-- performed by custom machines~-- used to dominate the time
spent in a typical genome-related project, the emphasis is migrating
to experimental design and datastream analysis.

The project described by Agarwal provides the computational
infrastructure for acceping and storing sequencing data and
sequencing, and making it accessible to distributed computations on a
compute cluster.  In particular, the Genomics Sequencing Core provides
an application server for managing the overall functioning of the
system, a job queue for computations that interfaces to the compute
cluster, and a web front end for the entire systems.  The system
maintains metadata tracking samples, libraries and protocols.

The data that accumulates in the system is characterized by high
volume, but also by a high variety of different formats.  (The
velocity at which it arrives is not yet a problem, but may become a
challenge in the future.)  Agarwal and his colleages have developed a
DSL embedded into OCaml that is used to generate multiple
functionalities, among them serialization, SQL schemas, query scripts,
OCaml code for performing reads in inserts, web widgets, and diagrams.
This enables rapid development of functionality, and easy migration
between formats.

The Core also maintains a virtual filesystem that distinguishes
between ``original'' data and recomputes ``derived'' data on the fly.

The entire system is implemented in OCaml, using a wide variety of
libraries~-- in particular the
Ocsigen~\cite{Balat:2009:ERO:1596550.1596595} web framework, the Core
and Batteries libraries, and the Biocaml, PG'OCaml, Xmlm and Ocamlnet
libraries.  ``1.3 developers'' built the system and delivered the
first version in production within two months.  The experience with
OCaml has been mostly positive: Agarwal cited OCaml's
industrial-strength implementation, the availability of needed
libraries, and the excellent performance.  Agarwal mentioned the
complications maintaining a build system and the lack of ``blessed
libraries'' as factors that could still be improved.

Agarwal closed by summarizing the standing of functional programming
in biology: Functional programming is becoming a recognized term, and
thus the field is developing demand for software engineers who can
acquire domain knowledge and build software fast.  He noted that this
profile is different from that of data analysts, who need more
in-depth knowledge of the field and statistics.

\section{Using F\# to Prove Stabilization of Biological Networks}

Samin Ishtiaq reported on the \textit{Bio Model
  Analyzer}~\cite{Benque:2012:BVT:2362216.2362280} (or \textit{BMA},
online at \url{http://biomodelanalyzer.research.microsoft.com/})
developed by an interdisciplinary team at Microsoft Research: The Bio
Model Analyzer analyzes models from System Biology, which are
program-like descriptions of networks that describe systems like skin
or blood.

Particularly important to BMA are \textit{stability} properties: For
example, healthy skin should grow as many cells as it sheds.  If it
sheds more than it grows, sores develop and wounds do not heal well.
Growing more than it sheds is the definition of cancer.

The programs describing such biological networks are asynchronous
dataflow diagrams with typically tens of thousands of variables.  Each
variable has an associated update function that computes a new value
from the the values of other variables connected with it in the
network.  The objective of BMA is not just to simlulate a network, but
to prove general stability-related properties independent of a
particular starting state, such as the existence of a unique fixpoint,
several fixpoints or cycles.  This may be useful for developing new
drugs.

Traditional program-analysis tools do not scale or do not work for
programs with this many variables.  Consequently, BMA uses newly
developed techniques: It attempts to prove lemmas for small
subnetworks and propagate them through the entire networks in the hope
that enough lemmas propagate to prove stability.  The prover core does
not just report on the success of the proof search, but also allows
interactively stepping through the lemma-propagation process.  The
designers in the BMA team have targeted the UI at system biologists,
which use visualizations different from those computer scientist

BMA consists of three parts: The prover core written in F\#,
Microsoft's Z3 SMT solver written in C++ (but only linked into the
project), and the UI written in C\#.  The ``debugging functionality''
in the prover provides the propagation steps in a lazy sequence.  This
is very natural in F\#.  The UI is not written in F\#: in particular,
it benefits from the better tool support for C\#.

Ishtiaq had previously worked in OCaml using Emacs, and offered some
thoughts on the transition to F\# in Visual Studio: In particular,
Visual Studio offers interactive type checking and thus supports
exploratory programming in ways Emacs does not.  On the other hand,
OCaml still offers some higher-level abstraction mechanisms such as
GADTs, modules, and functors, which F\# still lacks.

\section{Developing an F\# Bioinformatics Application with HTML5
  Visualization}

\section{Developing Medical Software in Scala and Haskell}

\section{Functional programs connected to the power grid}

\section{Clojure iPad analytics dashboard in energy sector}

\section{The Awesome Haskell FPGA Compiler}

\section{Conclusion}

We would like to thank Simon Thompson and Duncan Coutts for helping to
organize the CUFP tutorials, and Ashish Agarwal for organizing the BoF
sessions.  We thank Kresten Krab Thorup and Yaron Minsky for providing
notes on their talks.  Also, we thank Peter Thiemann and Fritz Henglein and the
whole ICFP/CUFP team for their assistance in Copenhagen.  We look
forward to CUFP 2013 in Boston!

\bibliography{biblio}
\end{document}

% end of JFP2egui.tex
